{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf2411a-b5a1-4d32-a60a-8e2215ba579b",
   "metadata": {},
   "source": [
    "## Week 1: Literature Review and Scope Definition \n",
    "\n",
    "After my kickstarter meeting with Professor Rachlin, I began reading and documenting relevant papers in the field of: Neural Network Hyperparameter Tuning, Multi-Objective Optimization and Evolutionary Deep Learning. These works provided me the necessary background to identify the research area: Multi-Objective Hyperparameter Optimization of Neural Network Architecture using Evolutionary Algorithms. \n",
    "\n",
    "Rather than relying on manual experimentation, which currently functions as a â€œblack artâ€, with no standardized protocol, using rational agents to iteratively evolve and optimize neural networks may, at best, provide such protocol or, at worst, provide information on relationships between configuration specifications and performance metrics. \n",
    "\n",
    "These agents not only adjust high-level hyperparameters, such as learning rates or activation functions, but also actively modify the structure of the network itself, including the number of layers, types of layers, and the interconnections between them. By formulating the problem as a multi-objective optimization task, the candidate solutions balance competing goals such as accuracy, complexity, and training efficiency. ML practicioners can use this research to assess which tradeoffs are important for their research and analysis objectives, and specify hyperparameters accordingly.\n",
    "\n",
    "Bayesian methods\n",
    "\n",
    "## Key Quotes\n",
    "- pg 1: But in many applications, we are not only interested in optimizing ML pipelines solely for predictive accuracy; additional metrics or constraints must be considered when determining an optimal configuration, resulting in a multi-objective optimization problem often neglected in practice, due to a lack of knowledge and readily available software implementations\n",
    "for multi-objective hyperparameter optimization\n",
    "- pg 1: existing optimization strategies, both from the domain of evolutionary algorithms and Bayesian optimization\n",
    "- pg 2: For a diagnostic test, solely looking at misclassification rates is ill-advised: Misclassifying a sick\n",
    "patient as healthy (false negative) has usually much more severe consequences than classifying a\n",
    "healthy person erroneously as sick (false positive), i.e., different misclassification costs, which are\n",
    "often unknown or hard to quantify, have to be considered\n",
    "- pg 2: This set of Pareto optimal\n",
    "solutions can then be analyzed by domain experts in a post-hoc manner, and an informed decision\n",
    "can be made as to which trade-off should be used in the application, without requiring the user to\n",
    "specify this a priori\n",
    "- We restrict the scope of this paper to the realm of supervised ML. Unsupervised ML, in contrast,\n",
    "entails a different set of metrics to the scenario studied in our manuscript and is largely governed\n",
    "by custom, use case-specific measures [87, 205] and sometimes even visual inspection of results\n",
    "- pg 3: We will categorize these\n",
    "applications through exploring three overarching perspectives on the ML process: (1) Performance\n",
    "metrics, (2) metrics that measure costs and restrictions at deployment like efficiency, and (3) metrics\n",
    "that enforce reliability and interpretability.\n",
    "- The fundamental ML problem can be defined as follows. **this entire paragraph**\n",
    "-  nested resampling techniques should be applied\n",
    "-  A simple alternative\n",
    "is simply splitting Doptim into two datasets Dtrain and Dval, which leads to the widely known\n",
    "train/validation/test-split\n",
    "- pg 5: The domain Î› of the problem is called numerical if only numeric hyperparameters ğ€ are optimized\n",
    "- By including additional\n",
    "- categorical hyperparameters, like the type of kernel used in a support sector machine (SVM),\n",
    "the search space becomes mixed numerical and categorical. Mixed search spaces already require\n",
    "adaption of some optimization strategies, such as BO, which we will discuss in Section 4.4. It\n",
    "can also be necessary to introduce further conditional hierarchies between hyperparameters. For\n",
    "example, when optimizing over different kernel types of an SVM, the ğ›¾ kernel hyperparameter is\n",
    "only valid if the kernel type is set to Radial Basis Function (RBF), while for a polynomial kernel, a\n",
    "hyperparameter for the polynomial degree must be specified. These conditional hierarchies can\n",
    "become highly complicated - especially when moving from pure HPO to optimizing over full ML\n",
    "pipelines, i.e., AutoML, or over neural network architectures, referred to as neural architecture\n",
    "search (NAS) [89, 202, 215]\n",
    "- Feature selection is a topic that borders MOHPO and multi-objective ML and is often\n",
    "handled in a multi-objective manner \n",
    "- 6:  fairness with respect to two subpopulations satisfies a specific\n",
    "value\n",
    "- 6:  It is the task of an ML practitioner to translate a real-world problem into an ML task - and therefore objectives and constraints - to measure the quality and feasibility of a given model\n",
    "- Analogously, we say a HPC ğ€ âˆˆ Î›Ëœ (Pareto-)dominates another configuration ğ€\n",
    "â€²\n",
    ", if and only if\n",
    "ğ‘(ğ€) â‰º ğ‘(ğ€\n",
    "â€²\n",
    "). In other words: ğ€ dominates ğ€\n",
    "â€²\n",
    ", if and only if there is no criterion ğ‘ğ‘–\n",
    "in which ğ€\n",
    "â€²\n",
    "is\n",
    "superior to ğ€, and at least one criterion ğ‘ğ‘—\n",
    "in which ğ€ is strictly better.\n",
    "- This situation arises if there exist ğ‘–, ğ‘— âˆˆ {1, . . . ,ğ‘š} for which ğ‘ğ‘– < ğ‘\n",
    "â€²\n",
    "ğ‘–\n",
    "but also\n",
    "ğ‘\n",
    "â€²\n",
    "ğ‘— < ğ‘ğ‘—\n",
    ". Hence, in contrast to single-objective optimization, there is in general no unique single\n",
    "best solution ğ€\n",
    "âˆ—\n",
    ", but a set of Pareto optimal solutions that are pairwise incomparable with regard\n",
    "to â‰º. This set of solutions is referred to as the Pareto (optimal) set and defined as\n",
    "P :=\n",
    "\b\n",
    "ğ€ âˆˆ Î›Ëœ\n",
    "| Âš ğ€\n",
    "â€²\n",
    "âˆˆ Î›Ëœ s.t. ğ€\n",
    "â€² â‰º ğ€\n",
    "\t\n",
    "- ted solution sets - i.e., within\n",
    "each set, no configuration is dominated by another configuration. The associated approximated\n",
    "Pareto fronts are denoted by PË†\n",
    "S1\n",
    "and PË†\n",
    "S2\n",
    "respectively. According to Zitzler et al. [2003], PË†\n",
    "S1\n",
    "is\n",
    "said to weakly dominate PË†\n",
    "S2\n",
    ", denoted as PË†\n",
    "S1 âª¯ PË†\n",
    "S2\n",
    ", if for every solution ğ€2 âˆˆ S2 there is at least\n",
    "one solution ğ€1 âˆˆ S1 which weakly dominates ğ€2. PË†\n",
    "S1\n",
    "is furthermore said to be better than PË†\n",
    "S2\n",
    ",\n",
    "denoted5\n",
    "as PË†\n",
    "S1\n",
    "âŠ³ PË†\n",
    "S2\n",
    ", if PË†\n",
    "S1 âª¯ PË†\n",
    "S2\n",
    ", but not every solution of PË†\n",
    "S1\n",
    "is weakly dominated by any\n",
    "solution in PË†\n",
    "S2\n",
    ", i.e., PË†\n",
    "S2 âª¯Ì¸ PË†\n",
    "S1\n",
    ". This represents the weakest form of superiority between two\n",
    "approximations of the Pareto front\n",
    "How well a single solution set\n",
    "represents the Pareto front can be divided into four qualities [170]:\n",
    "Convergence The proximity to the true Pareto front\n",
    "Spread The coverage of the Pareto front\n",
    "Uniformity The evenness of the distribution of the solutions\n",
    "Cardinality The number of solutions\n",
    "The importance of normalized\n",
    "objectives and various methods on how to implement them have been of interest within the multiobjective evolutionary computation community; even the particular effects on certain algorithms\n",
    "has been examined in detail\n",
    "\n",
    "Scalarization transforms a multi-objective goal into a single-objective one, i.e., it is a function\n",
    "ğ‘  : â„ğ‘š Ã— T â†’ â„ that maps ğ‘š criteria to a single criterion to be optimized, configured by\n",
    "scalarization hyperparameters ğ›¼ âˆˆ T. Having only one objective often simplifies the optimization\n",
    "problem [194]. However, there are two main drawbacks to using scalarization for MOO [141]:\n",
    "Firstly, the scalarization hyperparameters ğ›¼ must be chosen sensibly, such that the single-objective\n",
    "represents the desired relationship between the multiple criteria â€“ which is not trivial, especially\n",
    "without extensive prior knowledge of the optimization problem and not adequately represent a multi-objective problem with conflicting objectives\n",
    "\n",
    "\n",
    "## Confusing Statements\n",
    "- pg 2: However,\n",
    "it is often unclear how a trade-off between different objectives should be defined a priori, i.e., before\n",
    "possible alternative solutions are known\n",
    "- pg 2: many ML and data mining applications inherently concern trade-offs\n",
    "and thus should be approached via MOO methods\n",
    "- pg 2: And even if the main interest lies in a single\n",
    "objective it still might be advantageous to approach the problem via MOO methods since they\n",
    "have the potential to reduce local minima\n",
    "- Mixed and hierarchical search spaces can be\n",
    "treated with BO with special kernel functions3 or by using a suitable surrogate, e.g., random forests.\n",
    "- Evolutionary algorithms (Section 4.3), on the other hand, can not select HPCs as effectively as BO\n",
    "and thus usually need more proposals than BO; however, they propose HPCs naturally in batches\n",
    "and can handle mixed and hierarchical search spaces with ease because of the discrete nature of\n",
    "their proposal-generating operations.\n",
    "- To record the evaluated hyperparameter configurations and their respective scores, we introduce\n",
    "the so-called archive A = ( (ğ€\n",
    "(1)\n",
    ", ğ‘(ğ€\n",
    "(1)\n",
    ")), (ğ€\n",
    "(2)\n",
    ", ğ‘(ğ€\n",
    "(2)\n",
    ")), . . . ), with A[ğ‘¡+1] = A[ğ‘¡] âˆª (ğ€\n",
    "+\n",
    ", ğ‘(ğ€\n",
    "+\n",
    "))\n",
    "if a single configuration is presented by an algorithm that iteratively proposes hyperparameter\n",
    "configurations.\n",
    "-  Model parameters are fixed by the ML algorithm\n",
    "at training time in accordance to one or multiple metrics, whereas hyperparameters are chosen by\n",
    "the ML practitioner before training and influence the behavior of the learning algorithm and the\n",
    "structure of its associated hypothesis space.\n",
    "- While the search space is generally smaller for hyperparameter\n",
    "optimization, the problem tends to be more expensive as multiple evaluations of the ML algorithm\n",
    "are required. \n",
    "- Quality\n",
    "indicators that focus on all four qualities listed above can be divided into distance-based, which\n",
    "require the knowledge of the true Pareto front or a suitable approximation of it, and volume-based,\n",
    "which measure the volume between the approximated Pareto Front and a method-specific point.\n",
    "\n",
    "## Week 2: Evo Framework Familiarization and Strategy\n",
    "\n",
    "Professor Rachlin provided the most updated code of the Evo Framework to which I did a complete deep dive of the code base. First I went line by line, handwritting the code to understand the relationship between the Profile class, Environment class, decorators and the TA Assignment implementation. Once I understood how to define agents, objectives, solutions and the environment, I created schematics, UML diagrams and pseudocode to map out Python scripts for the MOHPO (Multi-Objective Hyperparameter Optimization) problem. \n",
    "\n",
    "Further exploring papers, I began brainstorming potential objective functions (i.e. training time, memory size, number of neurons, number of layers), agents (i.e. change layer type, change model optimizer,  \n",
    "\n",
    "How will the model be trained efficiently? we may need to enahce the evo framework to say maximizing or minimizing or objective. accuracy to error rate (just to get it to work). run the actual code and make sure you understand how it works\n",
    "\n",
    "how do i want to present the design of the neural net arch?\n",
    "no. of layers, no. of neurons, backpropagation, number of epochs\n",
    "\n",
    "how accurate is the network and there's different measurements of accuracy\n",
    "false positive, false negative (type I is fun, type II youre screwed in health diagnostics )\n",
    "\n",
    "what parameters should be considered:\n",
    "specific standardized acuracy. minimize the complexity of network, total number of nodes.\n",
    "\n",
    "should i be storing the models as pkl loads? and if self.model is not None then whatever? or should the computer be handling all of it in real time?\n",
    "\n",
    "F(Object[H,M, Metrics]) â€”> Number\n",
    "train_model()\n",
    "train_model(input_data)\n",
    "build_model()\n",
    "test_model()\n",
    "Agent(Solution) â€”> Soluion\n",
    "\n",
    "\n",
    "\n",
    "## Week 3: Introduction to Keras and Evo Framework Integration\n",
    "\n",
    "creating a solution object that has \n",
    "\n",
    "Learn Keras. Deep Learning with Python textbook. Write function to train and build and test the model. script I might write to build the neural network could be driven by hyperparameters. most of the models did not have that good of a performance\n",
    "\n",
    "Keep the architecture VERY simple \n",
    "\n",
    "Finally I was able to get the coding working but the first working iteration is resultling in a solution set that is empty. I wonder if there is some issue with how Pareto optimal solutions are calculated why this is happening.\n",
    "\n",
    "I am going to attempt to increase the number of layers to see if the additional complexity changes performance outcome.\n",
    "\n",
    "**NOTE:** So that was not the issue. Working in colab changes how you refer to files and directories referenced at run time and after the first 10 solutions were initiated the function call just ended. Why the solutions didn't stay in the populat I am not sure but that is the issue that is happening here.\n",
    "\n",
    "To be a good programmer you have to pay attention to the smallest of things. I kept getting a population of 0 for several reasons but one of the reasons was the constrains file initialized a max for time and because I was measuring in nanoseconds ALL of the algorithms went over time.\n",
    "\n",
    "Use iris dataset for simplicity\n",
    "\n",
    "'softmax' removing since requires unique specificity for units.. should i include it down the line?\n",
    "\n",
    "start basic hyperparametrs first. constrain the search space of possibilites...what would be the minimal specification of a neural network that i can construct and run against some dataset...start as simple as possible\n",
    "\n",
    "create an object model that has these 3 elements in them and stores them in a way that we can interrogate the object and get back out a metric\n",
    "\n",
    "## Week 4: Optimize Codebase \n",
    "\n",
    "I missed the meeting with Rachlin and prepared a report of the work I have done thus far. \n",
    "\n",
    "evo deep learning book. Look at news outlets to identify topics for datasets that would be relevant to use for analysis. Onsider astronomy and bioinformatics as Rachlin enjoys those. Incorporate a validation set that after the pareto set ofoptimal solutions is found, tested again on the validation set, this time reducing to the final set. Looking at how many configurations can be made in a short time span.  getting the Pareto optimal set of solutions and evaluating the different trade-offs (also fundamental trade off between accuracy and complexity. simplest neural network that still has good accuracy). the Number of Layers, CNN for image analysis and image net competitions. T\n",
    "\n",
    "remove sol.data from each solution instance, should only be one\n",
    "consider different types of layers: add `layers.Dropout(0.5)` dropout layers (applied to layer than comes before it) pg 151\n",
    "include other accuracy metrics (recall, precision, sensitivity, etc)\n",
    "change size to number of layers and number of neurons\n",
    "include validation set to filter out the final pareto optimal solutions\n",
    "keep the evolution as is. once you have finished, get the models from the solutions, validate them on the validation set, get the final scores and THEN show what the output is (maybe store all these metrics in metrics, but only focus on certain ones for objectives\n",
    "\n",
    "include addressing overfitting (looking for similar performance between test and train tests.\n",
    "find dataset with biomedical relevance\n",
    "add epochs as a hyperparameter\n",
    "keep track of the number of different archietectures you are able to generate per hour (10 is too few, 1000 is useful)\n",
    "show dashboard showing tradeoffs, so what's the relationship between the objectives (maybe can have pareto optimal solutions vs all solutions) --> is there a string positive correlation between increasing accuray and increasing complexity?\n",
    "\n",
    "review class materials on evo framework and deepl learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
